{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from can_llamas_drive.process_videos import Params\n",
    "from can_llamas_drive.video_worker import Video, VideoWorker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(\n",
    "    clip_model_path=\"./models/llava-v1.5-7b/mmproj-model-f16.gguf\",\n",
    "    llava_model_path=\"./models/llava-v1.5-7b/ggml-model-Q5_K_M.gguf\",\n",
    "    system_prompt=\"Enter system prompt here.\",  # You are the assitant of the driver of a car. When the driver fails to brake in a dangerous situation, you can perform an emergency stop. You are only expected to perform an emergency stop if an immediate collision is unavoidable, unnecessary emergency stops should be avoided as much as possible. The data you get are frames from the dashcam feed of the vehicle of the past 0.5 s from old to new, the interval between the frames is 0.1 s. Use the relative difference between the frames to estimate the velocities and behaviour for all road users relative to our car.\n",
    "    prompt=\"Enter prompt here.\",  # Based on the current frame and previous ones, do you trigger an emergency stop or not? Answer 'Yes' or 'No'.\n",
    "    context_length=4096,\n",
    "    number_of_gpu_layers=16,\n",
    "    seed=1337,\n",
    "    temperature=0.1,\n",
    "    number_of_frames_to_evaluate=3,\n",
    "    number_of_parallel_processes=1,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "frame_index = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate video frame(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = Video(\n",
    "    \"datasets/CarCrash/videos/Crash-1500/000001.mp4\",\n",
    "    is_crash=True,\n",
    "    is_ego_involved=True,\n",
    ")\n",
    "video_worker = None\n",
    "video_worker = VideoWorker(video, params)\n",
    "display(\n",
    "    Image.fromarray(\n",
    "        cv2.cvtColor(\n",
    "            video_worker.get_concatenated_frames(frame_index, axis=1), cv2.COLOR_BGR2RGB\n",
    "        )\n",
    "    )\n",
    ")\n",
    "answer = video_worker.get_answer(frame_index)\n",
    "print(answer[\"choices\"][0][\"message\"][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
